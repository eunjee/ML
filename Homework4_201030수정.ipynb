{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4_201030수정.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDCKOcyrVwV_",
        "outputId": "0c622d63-10ca-4940-f194-27342b7f0562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd5_904eWZf4"
      },
      "source": [
        "data_dir = '/gdrive/My Drive/colab/week4/data'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX0cKlTRWfzN"
      },
      "source": [
        "import re\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMC6p-WWhvr"
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm #progress bar를 보여주기 위함\n",
        "\n",
        "# line별로 읽어서 문장과 라벨을 나눔\n",
        "def load_data(file_path):\n",
        "  file = open(os.path.join(data_dir, file_path))\n",
        "\n",
        "  texts, labels = [], []\n",
        "\n",
        "  for line in tqdm(file.readlines()):\n",
        "    text, label = line.strip().split('\\t')\n",
        "    texts.append(text)\n",
        "    labels.append(label)\n",
        "  return texts, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBjws6WdWjx1",
        "outputId": "e7a19482-31eb-4e5b-cc07-95e4dec823af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_X, train_y = load_data('sentiment_train.txt')\n",
        "test_X, test_y = load_data('sentiment_test.txt')"
      ],
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2686/2686 [00:00<00:00, 829167.63it/s]\n",
            "100%|██████████| 300/300 [00:00<00:00, 168445.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad0IUyzOYiFo",
        "outputId": "df2ed54b-4d12-43ad-a24f-697ac75dbf18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_X[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "제품 도 너무 너무 맘 에 들 ㄴ답니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kurkbJpNWlLi",
        "outputId": "82f677a7-de99-4d0d-c730-9472cb85763c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(train_X))\n",
        "print(len(train_y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2686\n",
            "2686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rxet3cnXa6f"
      },
      "source": [
        "# Train Data 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS2d3dNhWtb2"
      },
      "source": [
        "#완성형 한글만 데이터로 사용\n",
        "def cleanText(document):\n",
        "  for i in range(len(document)):\n",
        "    document[i] = re.sub('[^가-힣\\s]','',document[i])\n",
        "  return document"
      ],
      "execution_count": 533,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpmtX7O-ZLrg"
      },
      "source": [
        "clean_train_X = cleanText(train_X)"
      ],
      "execution_count": 550,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVCLyf76Z3iG",
        "outputId": "91421a3d-80e6-4305-e8ee-14c00960ea0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_X[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "제품 도 너무 너무 맘 에 들 답니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKfGkHlFcbBz"
      },
      "source": [
        "# label을 이용해서 긍정문서와 부정문서를 나눈다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1K83jMIcSqQ"
      },
      "source": [
        "from operator import eq\n",
        "import re\n",
        "def split_train(train_X,train_y):\n",
        "  i=0\n",
        "  p_train, n_train = [],[]\n",
        "  for i in range(len(train_X)):\n",
        "    if 'P' in train_y[i]:\n",
        "      p_train.append(train_X[i])\n",
        "    elif 'N' in train_y[i]:\n",
        "      n_train.append(train_X[i])\n",
        "  return p_train, n_train"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYO1DjDjckjM"
      },
      "source": [
        "p_train, n_train = split_train(clean_train_X,train_y)"
      ],
      "execution_count": 551,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioeT78COhZZ"
      },
      "source": [
        "긍정문서와 부정문서로 부터 각각의 단어장을 구하고 tf vector를 구한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-hukXbAGUqc"
      },
      "source": [
        "count_vectorizer1 = CountVectorizer()\n",
        "count_vectorizer2 = CountVectorizer()\n",
        "p_count_vectorizer = count_vectorizer1.fit_transform(p_train).toarray()\n",
        "n_count_vectorizer = count_vectorizer2.fit_transform(n_train).toarray()"
      ],
      "execution_count": 577,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnN2po3G9Y8"
      },
      "source": [
        "p_vocabulary = list(sorted(count_vectorizer1.vocabulary_.keys()))\n",
        "n_vocabulary = list(sorted(count_vectorizer2.vocabulary_.keys()))"
      ],
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq4_SqB-cnfg",
        "outputId": "66051144-0f19-4d46-ccc4-8254fba2ba85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(p_vocabualry))\n",
        "print(p_count_vectorizer.shape)"
      ],
      "execution_count": 581,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1084\n",
            "(1084,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFrSne0ldcN7"
      },
      "source": [
        "p_tf = dict.fromkeys(p_vocabulary,0)\n",
        "n_tf = dict.fromkeys(n_vocabulary,0)\n",
        "p_count_vectorizer = np.sum(p_count_vectorizer,axis =0)\n",
        "n_count_vectorizer = np.sum(n_count_vectorizer,axis=0)"
      ],
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUa3L0uKK1iy"
      },
      "source": [
        "for i,key in enumerate(p_tf):\n",
        "  p_tf[key] = p_count_vectorizer[i]\n",
        "\n",
        "for i,key in enumerate(n_tf):\n",
        "  n_tf[key] = n_count_vectorizer[i]"
      ],
      "execution_count": 582,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWEuLPAfLRRE",
        "outputId": "fd15e5dc-4876-4ad3-e6b0-6fba8f65e7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(p_tf['제품'])"
      ],
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkFuMQGZd2rU"
      },
      "source": [
        "# TF-IDF 구하기 \n",
        "tf는 CountVectorizer이용\n",
        "\n",
        "idf는 따로 함수를 구현\n",
        "\n",
        "idf를 구할 때의 공식은 log10(2/df값)을 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5reH_eN95Es"
      },
      "source": [
        "import math\n",
        "\n",
        "def get_df(ptfv,ntfv,vocab):\n",
        "  dfv = dict.fromkeys(vocab,0)\n",
        "  for d in dfv:\n",
        "    if d in ptfv:\n",
        "      dfv[d]+=1\n",
        "    if d in ntfv:\n",
        "      dfv[d]+=1\n",
        "  return dfv\n",
        "\n",
        "def get_idf(ptfv,ntfv,vocab):\n",
        "  idfv = get_df(ptfv,ntfv,vocab)\n",
        "  for key, val in idfv.items():\n",
        "    idfv[key] = math.log10(2/float(val))\n",
        "  \n",
        "  return idfv"
      ],
      "execution_count": 587,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJ535FajG8P"
      },
      "source": [
        "p_idfv = get_idf(p_tf,n_tf,p_vocabulary)\n",
        "n_idfv = get_idf(p_tf,n_tf,n_vocabulary)"
      ],
      "execution_count": 588,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lxr0yafLt1n"
      },
      "source": [
        "#tf와 idfv곱하기\n",
        "p_tfidf = dict.fromkeys(p_vocabualry,0)\n",
        "n_tfidf = dict.fromkeys(n_vocabulary,0)\n",
        "for i,key in enumerate(p_vocabulary):\n",
        "  p_tfidf[key] = p_tf[key]*p_idfv[key]\n",
        "\n",
        "for i,key in enumerate(n_vocabulary):\n",
        "  n_tfidf[key] = n_tf[key]*n_idfv[key]"
      ],
      "execution_count": 590,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTVX45MUPQZv"
      },
      "source": [
        "# 긍정과 부정에서 각각 상위 100개의 단어 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIdfTNlTlWKu",
        "outputId": "51df7558-bfb7-428c-8781-71c6cee42858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p_dict = sorted(dict.items(p_tfidf),key=operator.itemgetter(1),reverse=True)\n",
        "p_dict = dict((x,y) for x,y in p_dict)\n",
        "\n",
        "n_dict = sorted(dict.items(n_tfidf),key=operator.itemgetter(1),reverse=True)\n",
        "n_dict= dict((x,y) for x,y in n_dict)"
      ],
      "execution_count": 591,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W91zWcRFl-UO"
      },
      "source": [
        "#긍정과 부정 단어 각각 100개 추출\n",
        "p_list = list(p_dict.keys())\n",
        "n_list = list(n_dict.keys())\n",
        "\n",
        "p_list = p_list[0:100]\n",
        "n_list = n_list[0:100]\n",
        "\n",
        "np_vocab =list(set(p_list).union(set(n_list)))"
      ],
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfOtPgtgmna8",
        "outputId": "ced79913-acd6-4c4c-a53f-86b7187d4b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(np_vocab))\n",
        "print(np_vocab)"
      ],
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "['욕실', '강원도', '수시', '무겁', '한가지', '장난', '독신자', '사고', '불안', '가격좋고디자인수려하고대용량이라정말편리하고좋습니다', '저녁', '교환', '다는데', '상하', '짜증', '그치', '어른', '강츄', '기쁘', '지르', '감사드림니다', '호스', '한테', '넉넉', '성의', '가게', '강추예요', '결제', '가격싸고', '어쩌', '쇼핑몰', '관리법', '감솨', '결국', '따로', '사시', '길이', '높이', '관련', '자체', '언제', '섬유유연제가', '화가', '구조', '라는', '강추입니다', '기본', '오히려', '자꾸', '제일', '갓난아이', '꼼꼼', '무조건', '기원', '장마철', '그런데', '개인', '질문', '똑같', '사도', '보내', '화이트', '반품', '완벽', '강추에요', '게시판', '가격땜에', '문의', '원래', '진동', '외부', '가동', '나가', '구김', '답변', '가구', '토요일', '세심', '감안', '감사하드라구요', '대충', '신속', '국산', '아쉬움', '어쨌든', '고민', '대단히', '주정', '베리', '다행', '기숙사', '아닌가요', '얘기', '단점', '대우전자', '나요', '정신', '나이드신', '값싸', '중요', '엉킴도', '업체', '공기방울', '이서', '어떻', '훌륭', '가격만족성능만족배송만족서어비스만족모두가좋네요', '무슨', '화요일', '배려', '적극', '재고', '노인', '가르치', '으니까', '여러', '좋구여', '몇일', '뒤지', '주신', '맞히', '쿠폰', '떨어지', '시장', '냐고', '가격까지맘에', '어렵', '하하', '사용법', '사과', '는다는', '저렵', '약하', '한마디', '가격배송폐가전수거', '전용', '새해', '굳이', '불만', '전기', '당일', '관계', '폐가', '강추합니다', '안심', '이해', '강추', '실망', '작동법', '그거', '그런', '시끄럽', '외관', '모습', '상쾌', '강추임돠', '각격', '에다', '습니까', '소비자', '아쉽', '담당자', '그것', '화면', '배송만', '나쁘', '가요', '금속', '다만', '행복', '사실', '조절', '아무래도', '애기', '하지만', '태도', '튼튼', '강강츄', '더니', '가전', '불경기', '취소', '다시', '가격빠른배송', '연결', '고도', '감수', '가스렌지', '그러나', '효율', '혼자사니깐딱인거같아요', '버튼', '부자', '지연', '가로', '시험', '대체로', '가량', '당근', '생활']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDjDh8jzPaJ3"
      },
      "source": [
        "np_vocab이 없는 문장은 제거해서 train한다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRBrMr16v9W2"
      },
      "source": [
        "#행의 합이 0인 array는 제거\n",
        "new_train_X=[]\n",
        "new_train_y=[]"
      ],
      "execution_count": 595,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF5d0t5HmzWk"
      },
      "source": [
        "for i,sentence in enumerate(train_X):\n",
        "  new_sent=''\n",
        "  for j, word in enumerate(np_vocab):\n",
        "    if word in sentence:\n",
        "     new_sent += word + ' '\n",
        "  if new_sent.strip()!='':\n",
        "    new_train_X.append(new_sent)\n",
        "    new_train_y.append(train_y[i])"
      ],
      "execution_count": 596,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_GQwBEa3Ae8",
        "outputId": "011f73fb-6077-43e0-dbdb-fa861d9d3238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(new_train_X),len(new_train_y))\n",
        "vectorizer = CountVectorizer()\n",
        "feature_train_X = vectorizer.fit_transform(new_train_X)"
      ],
      "execution_count": 597,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "741 741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uggZDdopRk_"
      },
      "source": [
        "# 학습!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_gzzIbPpQ27",
        "outputId": "fd3c1009-63c5-44af-fe23-0ca9f9f423d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifier = MultinomialNB()\n",
        "classifier.fit(feature_train_X,new_train_y)"
      ],
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxvxmLo0pGUe"
      },
      "source": [
        "# Test_X의 tf-idf구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0CBRzXK4FDu"
      },
      "source": [
        "new_test_X=[]\n",
        "new_test_y=[]\n",
        "for i,sentence in enumerate(test_X):\n",
        "  new_sent=''\n",
        "  for j, word in enumerate(np_vocab):\n",
        "    if word in sentence:\n",
        "     new_sent += word + ' '\n",
        "  if new_sent.strip()!='':\n",
        "    new_test_X.append(new_sent)\n",
        "    new_test_y.append(test_y[i])"
      ],
      "execution_count": 599,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAEEuqvRA1KU",
        "outputId": "aa396c9d-06a8-49f2-a8b2-5a611ab042fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(new_test_X),len(new_test_y))"
      ],
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxfrGNcQ37lJ"
      },
      "source": [
        "feature_test_X = vectorizer.transform(new_test_X)"
      ],
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxo6iQ2L0EVW"
      },
      "source": [
        "predictions = classifier.predict(feature_test_X).tolist()"
      ],
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw6XtqbS0NFT",
        "outputId": "7a258783-6cdc-40f3-8faf-57b97c5fa6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy: %.2f' % accuracy_score(new_test_y, predictions))"
      ],
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRhCegU4Aa5C",
        "outputId": "f8fea478-1606-4f11-ccdb-9bd3ae40ffe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(test_y[i],predictions[i])"
      ],
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<P> <N>\n",
            "<N> <P>\n",
            "<P> <N>\n",
            "<N> <N>\n",
            "<P> <N>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}